{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eda25c",
   "metadata": {},
   "source": [
    "This will try to parse resumes using OCR and fragmentation by blocks.\n",
    "First step is to define to target data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1dd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, fields\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class Resume:\n",
    "    name         : Optional[str]  = None\n",
    "    email        : Optional[str]  = None\n",
    "    phone        : Optional[str]  = None\n",
    "    education    : List           = field(default_factory=list)\n",
    "    experience   : List           = field(default_factory=list)\n",
    "    skills       : List           = field(default_factory=list)\n",
    "    introduction : Optional[str]  = None\n",
    "    technologies : List           = field(default_factory=list)\n",
    "    hyperlinks   : List           = field(default_factory=list)\n",
    "\n",
    "\n",
    "# Constantes para mostrar una seccion y elegir un CV\n",
    "CV_NUMBER        = 8\n",
    "\n",
    "SHOWCASE_SECTION = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4aa86",
   "metadata": {},
   "source": [
    "Enumerate the available resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7cece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import PyPDF2\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "POPPLER_PATH = (\n",
    "    r\"C:\\ProgramData\\chocolatey\\lib\\poppler-24.08.0\\Library\\bin\"\n",
    ")\n",
    "# 1) locate the first PDF\n",
    "resumes_dir = os.path.join(os.getcwd(), \"resumes\")\n",
    "files = os.listdir(resumes_dir)\n",
    "pdf_files = [f for f in files if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "if not pdf_files:\n",
    "    raise RuntimeError(\"No PDF found in resumes/\")\n",
    "\n",
    "first_pdf = pdf_files[CV_NUMBER]\n",
    "file_path = os.path.join(resumes_dir, first_pdf)\n",
    "print(f\"Loading {first_pdf!r}\")\n",
    "\n",
    "# 2) read its bytes and load into PyPDF2\n",
    "with open(file_path, \"rb\") as f:\n",
    "    pdf_bytes = f.read()\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))\n",
    "print(f\"→ {len(pdf_reader.pages)} pages\")\n",
    "\n",
    "# 3) convert only page 1 to a PIL.Image\n",
    "images = convert_from_bytes(\n",
    "    pdf_bytes,\n",
    "    dpi=450,\n",
    "    first_page=1,\n",
    "    last_page=1,\n",
    "    poppler_path=POPPLER_PATH\n",
    ")\n",
    "img = images[0]  # PIL.Image\n",
    "\n",
    "# 4) display inline in Jupyter\n",
    "plt.figure(figsize=(8, 11))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d86d47",
   "metadata": {},
   "source": [
    "Work in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176432f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# assume `img` is your original PIL page‐image\n",
    "\n",
    "# --- 0) PREPROCESSING: grayscale → binarize so text is black, background white ---\n",
    "gray_arr = np.array(img.convert(\"L\"))\n",
    "thresh = 128\n",
    "# ink mask: True where text (dark)\n",
    "ink = gray_arr < thresh\n",
    "# build a display image: 0=black text, 255=white bg\n",
    "bin_arr = np.where(ink, 0, 255).astype(\"uint8\")\n",
    "# replace img with the binarized version (RGB so we can draw red lines)\n",
    "img = Image.fromarray(bin_arr, mode=\"L\").convert(\"RGB\")\n",
    "\n",
    "# now `ink` is the same mask you’ll use below, and `img` is pure b/w for drawing\n",
    "w, h = img.size\n",
    "\n",
    "# 1) binary ink mask\n",
    "# (we already have `ink` from above, so you can drop the old gray<250 line)\n",
    "\n",
    "# 2) detect vertical splits\n",
    "col_sums = ink.sum(axis=0)\n",
    "min_v_gap = 50\n",
    "v_thresh = h * 0.01\n",
    "v_splits = []\n",
    "x = 0\n",
    "while x < w:\n",
    "    if col_sums[x] < v_thresh:\n",
    "        start = x\n",
    "        while x < w and col_sums[x] < v_thresh:\n",
    "            x += 1\n",
    "        end = x\n",
    "        if (end - start) >= min_v_gap:\n",
    "            v_splits.append((start + end)//2)\n",
    "    else:\n",
    "        x += 1\n",
    "\n",
    "# 3) define column dividers\n",
    "x_divs = [0] + v_splits + [w]\n",
    "\n",
    "# 4) find horizontal splits per column\n",
    "min_h_gap = 50\n",
    "h_splits_by_col = []\n",
    "for x0, x1 in zip(x_divs[:-1], x_divs[1:]):\n",
    "    sub = ink[:, x0:x1]\n",
    "    row_sums = sub.sum(axis=1)\n",
    "    h_thresh = (x1 - x0) * 0.01\n",
    "\n",
    "    ys = []\n",
    "    y = 0\n",
    "    while y < h:\n",
    "        if row_sums[y] < h_thresh:\n",
    "            start = y\n",
    "            while y < h and row_sums[y] < h_thresh:\n",
    "                y += 1\n",
    "            end = y\n",
    "            if (end - start) >= min_h_gap:\n",
    "                ys.append((start + end)//2)\n",
    "        else:\n",
    "            y += 1\n",
    "\n",
    "    h_splits_by_col.append(ys)\n",
    "\n",
    "# 5) draw the splits and collect rect info\n",
    "out = img.copy()\n",
    "draw = ImageDraw.Draw(out)\n",
    "for x in v_splits:\n",
    "    draw.line([(x, 0), (x, h)], fill=\"red\", width=3)\n",
    "\n",
    "sections = []\n",
    "for ci, (x0, x1) in enumerate(zip(x_divs[:-1], x_divs[1:])):\n",
    "    y_divs = [0] + h_splits_by_col[ci] + [h]\n",
    "    for ri, (y0, y1) in enumerate(zip(y_divs[:-1], y_divs[1:])):\n",
    "        draw.line([(x0, y1), (x1, y1)], fill=\"red\", width=4)\n",
    "        width = x1 - x0\n",
    "        height = y1 - y0\n",
    "        sections.append((ci, ri, x0, y0, width, height))\n",
    "\n",
    "# 6) print each section’s top-left and size\n",
    "print(f\"Found {len(sections)} sections:\")\n",
    "for ci, ri, x0, y0, w0, h0 in sections:\n",
    "    print(f\"  col {ci}, row {ri}: start=({x0},{y0}), \"\n",
    "          f\"width={w0}px, height={h0}px\")\n",
    "   \n",
    "# 7) display the image\n",
    "plt.figure(figsize=(8, 11))\n",
    "plt.imshow(out)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede385f",
   "metadata": {},
   "source": [
    "For each sections we can apply OCR algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Build a list of all section images\n",
    "section_imgs = []\n",
    "for idx, (ci, ri, x0, y0, w0, h0) in enumerate(sections):\n",
    "    sec = img.crop((x0, y0, x0 + w0, y0 + h0))\n",
    "    section_imgs.append(sec)\n",
    "\n",
    "# 3) Choose which one to display\n",
    "section_idx = SHOWCASE_SECTION\n",
    "ci, ri, x0, y0, w0, h0 = sections[section_idx]\n",
    "\n",
    "# 4) Grab it from the array\n",
    "sec_img = section_imgs[section_idx]\n",
    "\n",
    "# 5) Display at full (native) resolution\n",
    "dpi = plt.rcParams['figure.dpi']\n",
    "figsize = (w0 / dpi, h0 / dpi)\n",
    "plt.figure(figsize=figsize, dpi=dpi)\n",
    "plt.imshow(sec_img, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title(f\"Section {section_idx} \"\n",
    "          f\"(col={ci},row={ri}), {w0}×{h0}px\")\n",
    "\n",
    "# 6) (Optional) Show full page with that region highlighted\n",
    "out2 = img.copy()\n",
    "draw2 = ImageDraw.Draw(out2)\n",
    "draw2.rectangle(\n",
    "    [(x0, y0), (x0 + w0, y0 + h0)],\n",
    "    outline=\"blue\",\n",
    "    width=4\n",
    ")\n",
    "plt.figure(figsize=(8, 11))\n",
    "plt.imshow(out2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Full page with selected section highlighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b152a8",
   "metadata": {},
   "source": [
    "Por cada sección se va a extraer el texto a travez de Tesseract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982eed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array de imágenes PIL.Image.Image\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "# Filtrar section_imgs para quedarnos solo con las que tienen texto\n",
    "filtered = []\n",
    "for sec in section_imgs:\n",
    "    text = pytesseract.image_to_string(sec, lang=\"eng+spa\")\n",
    "    if text.strip():\n",
    "        filtered.append((sec, text))\n",
    "\n",
    "# Sobrescribimos section_imgs con sólo las imágenes no vacías\n",
    "section_imgs = [sec for sec, _ in filtered]\n",
    "text_sections = [txt for _, txt in filtered]\n",
    "\n",
    "# Imprimir índice y primeros 50 caracteres de cada texto detectado\n",
    "for i, text in enumerate(text_sections):\n",
    "    snippet = text.strip().replace(\"\\n\", \" \")\n",
    "    print(f\"{i}: {snippet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd05b5",
   "metadata": {},
   "source": [
    "El texto es extraido perfectamente. Despues de esto podemos revisar img por img que sea correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define a function to display one filtered section alongside its OCR snippet\n",
    "def show_section(idx):\n",
    "    \"\"\"\n",
    "    Display the idx-th filtered section image side-by-side with\n",
    "    its OCR snippet.\n",
    "    \"\"\"\n",
    "    sec_img, text = filtered[idx]\n",
    "    # Prepare the snippet (first 200 chars, single line)\n",
    "    snippet = text.strip().replace(\"\\n\", \" \")\n",
    "    print(snippet)\n",
    "    # Compute figure size: width = image_width + text_space, height = image_height\n",
    "    w, h = sec_img.size\n",
    "    dpi = plt.rcParams['figure.dpi']\n",
    "    # Give ~2 inches extra width for the text panel\n",
    "    figsize = ((w / dpi) + 2, h / dpi)\n",
    "    \n",
    "    # Create side-by-side axes\n",
    "    fig, (ax_img, ax_txt) = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    # Left: the cropped image\n",
    "    ax_img.imshow(sec_img)\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # Right: the text snippet\n",
    "    ax_txt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Optional, feel free to select a range of sections to read.\n",
    "# for i in range(len(filtered)):\n",
    "#     show_section(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b631fd6",
   "metadata": {},
   "source": [
    "Reto: Con el array de text_sections. Es posible llenar la estructura de datos usando NTLK? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "# Regex patterns\n",
    "_EMAIL_RE = re.compile(r\"[a-zA-Z0-9.+_-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z]+\")\n",
    "_PHONE_RE = re.compile(\n",
    "    r\"(?:\\+\\d{1,3}[\\s-]*)?\"      # optional +<1–3 digits> with spaces/hyphens\n",
    "    r\"(?:\\d[\\d\\s-]{6,}\\d)\"       # at least 8 digits total, interspersed with spaces/hyphens\n",
    ")\n",
    "_URL_RE   = re.compile(r\"https?://[^\\s]+|www\\.[^\\s]+\")\n",
    "\n",
    "def extract_email(text: str) -> Optional[str]:\n",
    "    \"\"\"Return the first email found in text, or None.\"\"\"\n",
    "    m = _EMAIL_RE.search(text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def extract_phone(text: str) -> Optional[str]:\n",
    "    \"\"\"Return the first phone number found in text, or None.\"\"\"\n",
    "    m = _PHONE_RE.search(text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def extract_urls(text: str) -> List[str]:\n",
    "    \"\"\"Return all URLs found in text (may be empty).\"\"\"\n",
    "    return _URL_RE.findall(text) or []\n",
    "\n",
    "email_list = list(dict.fromkeys(\n",
    "    e\n",
    "    for txt in text_sections\n",
    "    if (e := extract_email(txt)) is not None\n",
    "))\n",
    "\n",
    "phone_list = list(dict.fromkeys(\n",
    "    p\n",
    "    for txt in text_sections\n",
    "    if (p := extract_phone(txt)) is not None\n",
    "))\n",
    "\n",
    "url_list = list(dict.fromkeys(\n",
    "    u\n",
    "    for txt in text_sections\n",
    "    for u in extract_urls(txt)\n",
    "))\n",
    "text_sections = [text.replace(\"\\n\", \" \") for text in text_sections]\n",
    "\n",
    "print(json.dumps(text_sections, indent=2, ensure_ascii=False))\n",
    "# Build the resume\n",
    "resume = Resume()\n",
    "resume.email      = email_list[0] if email_list else None\n",
    "resume.phone      = phone_list[0].replace(\" \", \"\") if phone_list else None\n",
    "resume.hyperlinks = url_list\n",
    "\n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3a1e0",
   "metadata": {},
   "source": [
    "Con expresiones regulares se puede extraer correo y numero telefonico. El siguiente paso va a ser utilizar NLTK para extraer tecnologías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ce3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
